{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType \n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import col,array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('MusicGen') \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "train = spark.read.format(\"parquet\").load(\"train.parquet\")\n",
    "train.printSchema()\n",
    "\n",
    "n_rows = train.count()\n",
    "print(f\"N rows: \", n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WANTED_ROWS = 100_000\n",
    "frac = WANTED_ROWS / n_rows\n",
    "print(frac)\n",
    "\n",
    "sampled = train.sample(fraction=frac).toPandas()\n",
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nltk \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.util import pad_sequence\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data = [nltk.word_tokenize(text.lower()) for text in sampled[\"lyrics\"]]\n",
    "tokenized_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "std_data = [\n",
    "    list(\n",
    "        pad_sequence(tokens, n=3, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>')\n",
    "    ) for tokens in tokenized_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training, vocab = padded_everygram_pipeline(3, std_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MLE(3)\n",
    "model.fit(training, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_text(model, previous_text, n_tokens=10):\n",
    "    tokenized_previous = nltk.word_tokenize(previous_text.lower())\n",
    "    generated_text = model.generate(n_tokens, random_seed=1, text_seed=tokenized_previous)\n",
    "    texto_gerado = [token for token in generated_text if token != '<s>' and token != '</s>']\n",
    "    return ' '.join(texto_gerado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_text(model, 'The stars remind of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# f = open('baseline-model.pickle', 'wb')\n",
    "# pickle.dump(model, f)\n",
    "# f.close()\n",
    "f = open('baseline-model.pickle', 'rb')\n",
    "model = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.format(\"parquet\").load(\"test.parquet\")\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "TOKEN_REGEX = r'\\b\\w+\\b'\n",
    "def got_row_right(row, bd):\n",
    "    # music = row['lyrics']\n",
    "    music = row['lyrics']\n",
    "    model = bd.value\n",
    "    tokens = nltk.word_tokenize(music.lower())\n",
    "    # Get one random part of the music\n",
    "    i = randint(0, len(tokens) - N - 1)\n",
    "    \n",
    "    generated_text = model.generate(1, random_seed=1, text_seed=tokens[i:i+N])\n",
    "    texto_gerado = [token for token in generated_text if token != '<s>' and token != '</s>']\n",
    "    return texto_gerado == tokens[i+N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = sc.broadcast(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "res = test.rdd.map(got_row_right)\n",
    "\n",
    "for _ in range(10):\n",
    "    res_sample = res.sample(False, fraction=0.1)\n",
    "    right = res_sample.filter(lambda x: x).count()\n",
    "    wrong = res_sample.filter(lambda x: not x).count()\n",
    "    acc = right / (right + wrong)\n",
    "    print(f\"Right: {right}, Wrong: {wrong}, acc: {acc}\")\n",
    "    acc_list.append(acc)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
